{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSWvcGa70mffRInI4z1sNF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MEGH06/PINT/blob/main/PINT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "JaHY4TqnmuEY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_plants(row, window_size=60, stride=10, lai_scale=1000):\n",
        "    LAI = pd.to_numeric(row[1:1441]) * lai_scale\n",
        "    ETr = pd.to_numeric(row[1441:2881])\n",
        "    Tr = pd.to_numeric(row[2881:4321])\n",
        "\n",
        "    input_seqs=[]\n",
        "    target_seqs=[]\n",
        "\n",
        "    for start in range(0, len(LAI)-window_size +1 , stride):\n",
        "        end=start +window_size\n",
        "        X = np.stack([LAI[start:end], ETr[start:end]],axis=1)\n",
        "        Y=Tr[start:end]\n",
        "\n",
        "        input_seqs.append(X)\n",
        "        target_seqs.append(Y)\n",
        "\n",
        "    return input_seqs, target_seqs"
      ],
      "metadata": {
        "id": "knPAxAfqbYoT"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PlantDataset(Dataset):\n",
        "    def __init__(self, csv_path, window_size=60, stride=10, lai_scale=1000):\n",
        "        self.df = pd.read_csv(csv_path).values\n",
        "        self.input_seqs = []\n",
        "        self.target_seqs = []\n",
        "\n",
        "        for row in self.df:\n",
        "            X, Y = preprocess_plants(row, window_size, stride, lai_scale)\n",
        "            X = [np.array(x, dtype=np.float32) for x in X]\n",
        "            Y = [np.array(y, dtype=np.float32) for y in Y]\n",
        "            self.input_seqs.extend(X)\n",
        "            self.target_seqs.extend(Y)\n",
        "\n",
        "        self.input_seqs = np.array(self.input_seqs, dtype=np.float32)\n",
        "        self.target_seqs = np.array(self.target_seqs, dtype=np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_seqs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X = torch.from_numpy(self.input_seqs[idx])\n",
        "        Y = torch.from_numpy(self.target_seqs[idx])\n",
        "        return X, Y\n"
      ],
      "metadata": {
        "id": "bEaYvNV1pOSu"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plant_paths = {\n",
        "    \"MZ\": \"/content/MZ_plants.csv\",\n",
        "    \"FM\": \"/content/FM_plants.csv\",\n",
        "    \"SG\": \"/content/SG_plants.csv\",\n",
        "    \"PM\": \"/content/PM_plants.csv\"\n",
        "}\n",
        "\n",
        "plant_data = {}\n",
        "for plant, path in plant_paths.items():\n",
        "    dataset = PlantDataset(path)\n",
        "    loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "    plant_data[plant] = loader\n"
      ],
      "metadata": {
        "id": "7beSjTkEH-aZ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PINT(nn.Module):\n",
        "  def __init__(self, input_dim=2, hidden_dim=64, num_layer=3):\n",
        "    super().__init__()\n",
        "    self.lstm=nn.LSTM(input_dim, hidden_dim, num_layer, batch_first=True)\n",
        "    self.fc=nn.Linear(hidden_dim,1)\n",
        "\n",
        "    self.beta_unconstrained=nn.Parameter(torch.tensor(0.4))\n",
        "\n",
        "  def forward(self,x):\n",
        "    lstm_out,_ =self.lstm(x)\n",
        "    out=self.fc(lstm_out).squeeze(-1)\n",
        "    return out\n",
        "\n",
        "  def beta_learn(self):\n",
        "    return 0.1+ 0.7* torch.sigmoid(self.beta_unconstrained)"
      ],
      "metadata": {
        "id": "49IkzPS-0IQy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def phy_loss(Tr_pred,LAI,ETr,beta):\n",
        "  Tr_calc=(1-torch.exp(-beta*LAI))*ETr\n",
        "  loss=nn.MSELoss()(Tr_pred, Tr_calc)\n",
        "  return loss"
      ],
      "metadata": {
        "id": "QIW5qr82-hRR"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = PINT(input_dim=2, hidden_dim=64, num_layer=3).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "vV3JpqtAq7Am"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_st(model, optimizer, batch, lambda_bal= 1):\n",
        "  model.train()\n",
        "  X,Y =batch\n",
        "  X,Y=X.to(device), Y.to(device)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  Tr_pred=model(X)\n",
        "  beta=model.beta_learn()\n",
        "\n",
        "  LAI=X[:, :,0]\n",
        "  ETr=X[:, :,1]\n",
        "\n",
        "  data_loss=nn.MSELoss()(Tr_pred, Y)\n",
        "  phys_loss=phy_loss(Tr_pred, LAI, ETr, beta)\n",
        "  total_loss=data_loss+lambda_bal* phys_loss\n",
        "\n",
        "  total_loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  return total_loss.item(), data_loss.item(), phys_loss.item(), beta.item()"
      ],
      "metadata": {
        "id": "QHW2EuV-DVAL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, train_loader, num_epochs):\n",
        "    beta_log = []\n",
        "    loss_log = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        total_data_loss = 0.0\n",
        "        total_phys_loss = 0.0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            batch_loss, data_loss, phys_loss, beta_val = training_st(model, optimizer, batch)\n",
        "            total_loss += batch_loss\n",
        "            total_data_loss += data_loss\n",
        "            total_phys_loss += phys_loss\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        avg_data_loss = total_data_loss / len(train_loader)\n",
        "        avg_phys_loss = total_phys_loss / len(train_loader)\n",
        "\n",
        "        beta_log.append(beta_val)\n",
        "        loss_log.append((avg_loss, avg_data_loss, avg_phys_loss))\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {avg_loss:.4f} | \"\n",
        "              f\"Data Loss: {avg_data_loss:.4f} | Phys Loss: {avg_phys_loss:.4f} | \"\n",
        "              f\"β: {beta_val:.4f}\")\n",
        "\n",
        "    return beta_log, loss_log"
      ],
      "metadata": {
        "id": "gexFL5g4FeE8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 50\n",
        "beta_history, loss_history = train(model, optimizer, plant_data['MZ'], num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViRc7ppyq3NI",
        "outputId": "7d4cbc9c-938d-4b3d-9024-46038229ca08"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50 | Loss: 0.0064 | Data Loss: 0.0021 | Phys Loss: 0.0043 | β: 0.5170\n",
            "Epoch 2/50 | Loss: 0.0064 | Data Loss: 0.0020 | Phys Loss: 0.0043 | β: 0.5140\n",
            "Epoch 3/50 | Loss: 0.0063 | Data Loss: 0.0020 | Phys Loss: 0.0043 | β: 0.5109\n",
            "Epoch 4/50 | Loss: 0.0063 | Data Loss: 0.0020 | Phys Loss: 0.0043 | β: 0.5074\n",
            "Epoch 5/50 | Loss: 0.0063 | Data Loss: 0.0020 | Phys Loss: 0.0043 | β: 0.5044\n",
            "Epoch 6/50 | Loss: 0.0063 | Data Loss: 0.0020 | Phys Loss: 0.0043 | β: 0.5008\n",
            "Epoch 7/50 | Loss: 0.0063 | Data Loss: 0.0020 | Phys Loss: 0.0043 | β: 0.4978\n",
            "Epoch 8/50 | Loss: 0.0063 | Data Loss: 0.0020 | Phys Loss: 0.0043 | β: 0.4943\n",
            "Epoch 9/50 | Loss: 0.0063 | Data Loss: 0.0020 | Phys Loss: 0.0043 | β: 0.4910\n",
            "Epoch 10/50 | Loss: 0.0063 | Data Loss: 0.0020 | Phys Loss: 0.0043 | β: 0.4877\n",
            "Epoch 11/50 | Loss: 0.0062 | Data Loss: 0.0020 | Phys Loss: 0.0043 | β: 0.4837\n",
            "Epoch 12/50 | Loss: 0.0062 | Data Loss: 0.0020 | Phys Loss: 0.0042 | β: 0.4811\n",
            "Epoch 13/50 | Loss: 0.0061 | Data Loss: 0.0019 | Phys Loss: 0.0042 | β: 0.4783\n",
            "Epoch 14/50 | Loss: 0.0061 | Data Loss: 0.0019 | Phys Loss: 0.0042 | β: 0.4761\n",
            "Epoch 15/50 | Loss: 0.0061 | Data Loss: 0.0019 | Phys Loss: 0.0042 | β: 0.4745\n",
            "Epoch 16/50 | Loss: 0.0061 | Data Loss: 0.0019 | Phys Loss: 0.0042 | β: 0.4725\n",
            "Epoch 17/50 | Loss: 0.0061 | Data Loss: 0.0019 | Phys Loss: 0.0042 | β: 0.4702\n",
            "Epoch 18/50 | Loss: 0.0061 | Data Loss: 0.0019 | Phys Loss: 0.0042 | β: 0.4681\n",
            "Epoch 19/50 | Loss: 0.0060 | Data Loss: 0.0019 | Phys Loss: 0.0041 | β: 0.4660\n",
            "Epoch 20/50 | Loss: 0.0060 | Data Loss: 0.0019 | Phys Loss: 0.0041 | β: 0.4653\n",
            "Epoch 21/50 | Loss: 0.0059 | Data Loss: 0.0018 | Phys Loss: 0.0041 | β: 0.4644\n",
            "Epoch 22/50 | Loss: 0.0058 | Data Loss: 0.0018 | Phys Loss: 0.0040 | β: 0.4632\n",
            "Epoch 23/50 | Loss: 0.0061 | Data Loss: 0.0020 | Phys Loss: 0.0042 | β: 0.4623\n",
            "Epoch 24/50 | Loss: 0.0061 | Data Loss: 0.0019 | Phys Loss: 0.0042 | β: 0.4604\n",
            "Epoch 25/50 | Loss: 0.0059 | Data Loss: 0.0018 | Phys Loss: 0.0041 | β: 0.4599\n",
            "Epoch 26/50 | Loss: 0.0056 | Data Loss: 0.0017 | Phys Loss: 0.0039 | β: 0.4593\n",
            "Epoch 27/50 | Loss: 0.0055 | Data Loss: 0.0017 | Phys Loss: 0.0038 | β: 0.4578\n",
            "Epoch 28/50 | Loss: 0.0052 | Data Loss: 0.0017 | Phys Loss: 0.0035 | β: 0.4568\n",
            "Epoch 29/50 | Loss: 0.0053 | Data Loss: 0.0017 | Phys Loss: 0.0036 | β: 0.4559\n",
            "Epoch 30/50 | Loss: 0.0055 | Data Loss: 0.0017 | Phys Loss: 0.0038 | β: 0.4545\n",
            "Epoch 31/50 | Loss: 0.0068 | Data Loss: 0.0023 | Phys Loss: 0.0044 | β: 0.4524\n",
            "Epoch 32/50 | Loss: 0.0062 | Data Loss: 0.0020 | Phys Loss: 0.0043 | β: 0.4456\n",
            "Epoch 33/50 | Loss: 0.0061 | Data Loss: 0.0019 | Phys Loss: 0.0042 | β: 0.4419\n",
            "Epoch 34/50 | Loss: 0.0060 | Data Loss: 0.0019 | Phys Loss: 0.0041 | β: 0.4397\n",
            "Epoch 35/50 | Loss: 0.0059 | Data Loss: 0.0018 | Phys Loss: 0.0041 | β: 0.4386\n",
            "Epoch 36/50 | Loss: 0.0058 | Data Loss: 0.0018 | Phys Loss: 0.0040 | β: 0.4376\n",
            "Epoch 37/50 | Loss: 0.0055 | Data Loss: 0.0017 | Phys Loss: 0.0038 | β: 0.4368\n",
            "Epoch 38/50 | Loss: 0.0064 | Data Loss: 0.0021 | Phys Loss: 0.0043 | β: 0.4328\n",
            "Epoch 39/50 | Loss: 0.0058 | Data Loss: 0.0018 | Phys Loss: 0.0040 | β: 0.4313\n",
            "Epoch 40/50 | Loss: 0.0060 | Data Loss: 0.0019 | Phys Loss: 0.0041 | β: 0.4308\n",
            "Epoch 41/50 | Loss: 0.0061 | Data Loss: 0.0019 | Phys Loss: 0.0042 | β: 0.4279\n",
            "Epoch 42/50 | Loss: 0.0058 | Data Loss: 0.0018 | Phys Loss: 0.0040 | β: 0.4253\n",
            "Epoch 43/50 | Loss: 0.0057 | Data Loss: 0.0018 | Phys Loss: 0.0038 | β: 0.4239\n",
            "Epoch 44/50 | Loss: 0.0059 | Data Loss: 0.0018 | Phys Loss: 0.0041 | β: 0.4221\n",
            "Epoch 45/50 | Loss: 0.0057 | Data Loss: 0.0018 | Phys Loss: 0.0039 | β: 0.4211\n",
            "Epoch 46/50 | Loss: 0.0054 | Data Loss: 0.0017 | Phys Loss: 0.0037 | β: 0.4200\n",
            "Epoch 47/50 | Loss: 0.0054 | Data Loss: 0.0017 | Phys Loss: 0.0037 | β: 0.4191\n",
            "Epoch 48/50 | Loss: 0.0058 | Data Loss: 0.0019 | Phys Loss: 0.0039 | β: 0.4171\n",
            "Epoch 49/50 | Loss: 0.0051 | Data Loss: 0.0016 | Phys Loss: 0.0035 | β: 0.4157\n",
            "Epoch 50/50 | Loss: 0.0046 | Data Loss: 0.0016 | Phys Loss: 0.0031 | β: 0.4152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 50\n",
        "beta_history, loss_history = train(model, optimizer, plant_data['FM'], num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-EuWa-gtpJq",
        "outputId": "762ca5cf-54fa-4671-8d65-a899de496160"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50 | Loss: 0.0026 | Data Loss: 0.0013 | Phys Loss: 0.0013 | β: 0.4324\n",
            "Epoch 2/50 | Loss: 0.0034 | Data Loss: 0.0015 | Phys Loss: 0.0019 | β: 0.4406\n",
            "Epoch 3/50 | Loss: 0.0023 | Data Loss: 0.0011 | Phys Loss: 0.0012 | β: 0.4485\n",
            "Epoch 4/50 | Loss: 0.0023 | Data Loss: 0.0011 | Phys Loss: 0.0012 | β: 0.4572\n",
            "Epoch 5/50 | Loss: 0.0013 | Data Loss: 0.0007 | Phys Loss: 0.0006 | β: 0.4664\n",
            "Epoch 6/50 | Loss: 0.0011 | Data Loss: 0.0007 | Phys Loss: 0.0004 | β: 0.4730\n",
            "Epoch 7/50 | Loss: 0.0010 | Data Loss: 0.0007 | Phys Loss: 0.0003 | β: 0.4806\n",
            "Epoch 8/50 | Loss: 0.0007 | Data Loss: 0.0006 | Phys Loss: 0.0002 | β: 0.4878\n",
            "Epoch 9/50 | Loss: 0.0008 | Data Loss: 0.0006 | Phys Loss: 0.0002 | β: 0.4939\n",
            "Epoch 10/50 | Loss: 0.0007 | Data Loss: 0.0005 | Phys Loss: 0.0001 | β: 0.5000\n",
            "Epoch 11/50 | Loss: 0.0008 | Data Loss: 0.0006 | Phys Loss: 0.0002 | β: 0.5053\n",
            "Epoch 12/50 | Loss: 0.0008 | Data Loss: 0.0006 | Phys Loss: 0.0002 | β: 0.5104\n",
            "Epoch 13/50 | Loss: 0.0007 | Data Loss: 0.0006 | Phys Loss: 0.0002 | β: 0.5163\n",
            "Epoch 14/50 | Loss: 0.0007 | Data Loss: 0.0005 | Phys Loss: 0.0001 | β: 0.5214\n",
            "Epoch 15/50 | Loss: 0.0007 | Data Loss: 0.0006 | Phys Loss: 0.0001 | β: 0.5267\n",
            "Epoch 16/50 | Loss: 0.0008 | Data Loss: 0.0006 | Phys Loss: 0.0002 | β: 0.5319\n",
            "Epoch 17/50 | Loss: 0.0011 | Data Loss: 0.0007 | Phys Loss: 0.0004 | β: 0.5367\n",
            "Epoch 18/50 | Loss: 0.0007 | Data Loss: 0.0005 | Phys Loss: 0.0001 | β: 0.5412\n",
            "Epoch 19/50 | Loss: 0.0006 | Data Loss: 0.0005 | Phys Loss: 0.0001 | β: 0.5454\n",
            "Epoch 20/50 | Loss: 0.0007 | Data Loss: 0.0005 | Phys Loss: 0.0001 | β: 0.5500\n",
            "Epoch 21/50 | Loss: 0.0009 | Data Loss: 0.0006 | Phys Loss: 0.0003 | β: 0.5539\n",
            "Epoch 22/50 | Loss: 0.0006 | Data Loss: 0.0005 | Phys Loss: 0.0001 | β: 0.5584\n",
            "Epoch 23/50 | Loss: 0.0007 | Data Loss: 0.0006 | Phys Loss: 0.0001 | β: 0.5622\n",
            "Epoch 24/50 | Loss: 0.0006 | Data Loss: 0.0005 | Phys Loss: 0.0001 | β: 0.5677\n",
            "Epoch 25/50 | Loss: 0.0006 | Data Loss: 0.0005 | Phys Loss: 0.0001 | β: 0.5716\n",
            "Epoch 26/50 | Loss: 0.0007 | Data Loss: 0.0006 | Phys Loss: 0.0002 | β: 0.5750\n",
            "Epoch 27/50 | Loss: 0.0007 | Data Loss: 0.0006 | Phys Loss: 0.0002 | β: 0.5785\n",
            "Epoch 28/50 | Loss: 0.0007 | Data Loss: 0.0006 | Phys Loss: 0.0001 | β: 0.5818\n",
            "Epoch 29/50 | Loss: 0.0006 | Data Loss: 0.0005 | Phys Loss: 0.0001 | β: 0.5848\n",
            "Epoch 30/50 | Loss: 0.0008 | Data Loss: 0.0006 | Phys Loss: 0.0002 | β: 0.5881\n",
            "Epoch 31/50 | Loss: 0.0006 | Data Loss: 0.0005 | Phys Loss: 0.0001 | β: 0.5916\n",
            "Epoch 32/50 | Loss: 0.0006 | Data Loss: 0.0005 | Phys Loss: 0.0001 | β: 0.5947\n",
            "Epoch 33/50 | Loss: 0.0007 | Data Loss: 0.0006 | Phys Loss: 0.0002 | β: 0.5980\n",
            "Epoch 34/50 | Loss: 0.0007 | Data Loss: 0.0005 | Phys Loss: 0.0001 | β: 0.6006\n",
            "Epoch 35/50 | Loss: 0.0006 | Data Loss: 0.0005 | Phys Loss: 0.0001 | β: 0.6040\n",
            "Epoch 36/50 | Loss: 0.0006 | Data Loss: 0.0005 | Phys Loss: 0.0001 | β: 0.6072\n",
            "Epoch 37/50 | Loss: 0.0006 | Data Loss: 0.0005 | Phys Loss: 0.0001 | β: 0.6103\n",
            "Epoch 38/50 | Loss: 0.0006 | Data Loss: 0.0005 | Phys Loss: 0.0001 | β: 0.6132\n",
            "Epoch 39/50 | Loss: 0.0006 | Data Loss: 0.0005 | Phys Loss: 0.0001 | β: 0.6160\n",
            "Epoch 40/50 | Loss: 0.0006 | Data Loss: 0.0005 | Phys Loss: 0.0001 | β: 0.6186\n",
            "Epoch 41/50 | Loss: 0.0007 | Data Loss: 0.0005 | Phys Loss: 0.0002 | β: 0.6218\n",
            "Epoch 42/50 | Loss: 0.0006 | Data Loss: 0.0005 | Phys Loss: 0.0001 | β: 0.6244\n",
            "Epoch 43/50 | Loss: 0.0006 | Data Loss: 0.0005 | Phys Loss: 0.0001 | β: 0.6272\n",
            "Epoch 44/50 | Loss: 0.0006 | Data Loss: 0.0005 | Phys Loss: 0.0001 | β: 0.6297\n",
            "Epoch 45/50 | Loss: 0.0006 | Data Loss: 0.0005 | Phys Loss: 0.0001 | β: 0.6321\n",
            "Epoch 46/50 | Loss: 0.0007 | Data Loss: 0.0005 | Phys Loss: 0.0001 | β: 0.6348\n",
            "Epoch 47/50 | Loss: 0.0006 | Data Loss: 0.0005 | Phys Loss: 0.0001 | β: 0.6377\n",
            "Epoch 48/50 | Loss: 0.0007 | Data Loss: 0.0005 | Phys Loss: 0.0002 | β: 0.6403\n",
            "Epoch 49/50 | Loss: 0.0011 | Data Loss: 0.0007 | Phys Loss: 0.0005 | β: 0.6427\n",
            "Epoch 50/50 | Loss: 0.0006 | Data Loss: 0.0005 | Phys Loss: 0.0001 | β: 0.6451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 50\n",
        "beta_history, loss_history = train(model, optimizer, plant_data['PM'], num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqaDflDkt-Bj",
        "outputId": "9c9ebe9c-fdd6-4dde-e79b-08be2ac79dbd"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50 | Loss: 0.0095 | Data Loss: 0.0046 | Phys Loss: 0.0049 | β: 0.6454\n",
            "Epoch 2/50 | Loss: 0.0099 | Data Loss: 0.0042 | Phys Loss: 0.0057 | β: 0.6452\n",
            "Epoch 3/50 | Loss: 0.0097 | Data Loss: 0.0042 | Phys Loss: 0.0054 | β: 0.6450\n",
            "Epoch 4/50 | Loss: 0.0105 | Data Loss: 0.0046 | Phys Loss: 0.0059 | β: 0.6448\n",
            "Epoch 5/50 | Loss: 0.0102 | Data Loss: 0.0043 | Phys Loss: 0.0058 | β: 0.6446\n",
            "Epoch 6/50 | Loss: 0.0102 | Data Loss: 0.0043 | Phys Loss: 0.0059 | β: 0.6441\n",
            "Epoch 7/50 | Loss: 0.0099 | Data Loss: 0.0042 | Phys Loss: 0.0057 | β: 0.6438\n",
            "Epoch 8/50 | Loss: 0.0095 | Data Loss: 0.0042 | Phys Loss: 0.0053 | β: 0.6436\n",
            "Epoch 9/50 | Loss: 0.0096 | Data Loss: 0.0045 | Phys Loss: 0.0051 | β: 0.6433\n",
            "Epoch 10/50 | Loss: 0.0101 | Data Loss: 0.0042 | Phys Loss: 0.0058 | β: 0.6431\n",
            "Epoch 11/50 | Loss: 0.0097 | Data Loss: 0.0042 | Phys Loss: 0.0056 | β: 0.6430\n",
            "Epoch 12/50 | Loss: 0.0101 | Data Loss: 0.0043 | Phys Loss: 0.0058 | β: 0.6425\n",
            "Epoch 13/50 | Loss: 0.0097 | Data Loss: 0.0042 | Phys Loss: 0.0055 | β: 0.6424\n",
            "Epoch 14/50 | Loss: 0.0096 | Data Loss: 0.0042 | Phys Loss: 0.0054 | β: 0.6422\n",
            "Epoch 15/50 | Loss: 0.0093 | Data Loss: 0.0042 | Phys Loss: 0.0051 | β: 0.6420\n",
            "Epoch 16/50 | Loss: 0.0097 | Data Loss: 0.0043 | Phys Loss: 0.0055 | β: 0.6419\n",
            "Epoch 17/50 | Loss: 0.0098 | Data Loss: 0.0045 | Phys Loss: 0.0054 | β: 0.6416\n",
            "Epoch 18/50 | Loss: 0.0100 | Data Loss: 0.0042 | Phys Loss: 0.0058 | β: 0.6413\n",
            "Epoch 19/50 | Loss: 0.0099 | Data Loss: 0.0042 | Phys Loss: 0.0057 | β: 0.6411\n",
            "Epoch 20/50 | Loss: 0.0099 | Data Loss: 0.0042 | Phys Loss: 0.0057 | β: 0.6406\n",
            "Epoch 21/50 | Loss: 0.0096 | Data Loss: 0.0043 | Phys Loss: 0.0054 | β: 0.6403\n",
            "Epoch 22/50 | Loss: 0.0095 | Data Loss: 0.0042 | Phys Loss: 0.0053 | β: 0.6401\n",
            "Epoch 23/50 | Loss: 0.0094 | Data Loss: 0.0042 | Phys Loss: 0.0051 | β: 0.6398\n",
            "Epoch 24/50 | Loss: 0.0097 | Data Loss: 0.0042 | Phys Loss: 0.0055 | β: 0.6393\n",
            "Epoch 25/50 | Loss: 0.0097 | Data Loss: 0.0043 | Phys Loss: 0.0054 | β: 0.6390\n",
            "Epoch 26/50 | Loss: 0.0100 | Data Loss: 0.0043 | Phys Loss: 0.0057 | β: 0.6385\n",
            "Epoch 27/50 | Loss: 0.0098 | Data Loss: 0.0042 | Phys Loss: 0.0056 | β: 0.6381\n",
            "Epoch 28/50 | Loss: 0.0097 | Data Loss: 0.0042 | Phys Loss: 0.0055 | β: 0.6377\n",
            "Epoch 29/50 | Loss: 0.0100 | Data Loss: 0.0042 | Phys Loss: 0.0059 | β: 0.6373\n",
            "Epoch 30/50 | Loss: 0.0098 | Data Loss: 0.0042 | Phys Loss: 0.0056 | β: 0.6368\n",
            "Epoch 31/50 | Loss: 0.0098 | Data Loss: 0.0043 | Phys Loss: 0.0055 | β: 0.6365\n",
            "Epoch 32/50 | Loss: 0.0098 | Data Loss: 0.0042 | Phys Loss: 0.0056 | β: 0.6359\n",
            "Epoch 33/50 | Loss: 0.0097 | Data Loss: 0.0042 | Phys Loss: 0.0056 | β: 0.6354\n",
            "Epoch 34/50 | Loss: 0.0095 | Data Loss: 0.0042 | Phys Loss: 0.0053 | β: 0.6351\n",
            "Epoch 35/50 | Loss: 0.0098 | Data Loss: 0.0042 | Phys Loss: 0.0055 | β: 0.6346\n",
            "Epoch 36/50 | Loss: 0.0095 | Data Loss: 0.0043 | Phys Loss: 0.0052 | β: 0.6342\n",
            "Epoch 37/50 | Loss: 0.0104 | Data Loss: 0.0043 | Phys Loss: 0.0061 | β: 0.6339\n",
            "Epoch 38/50 | Loss: 0.0101 | Data Loss: 0.0042 | Phys Loss: 0.0059 | β: 0.6335\n",
            "Epoch 39/50 | Loss: 0.0100 | Data Loss: 0.0042 | Phys Loss: 0.0058 | β: 0.6329\n",
            "Epoch 40/50 | Loss: 0.0099 | Data Loss: 0.0042 | Phys Loss: 0.0057 | β: 0.6318\n",
            "Epoch 41/50 | Loss: 0.0098 | Data Loss: 0.0042 | Phys Loss: 0.0056 | β: 0.6312\n",
            "Epoch 42/50 | Loss: 0.0102 | Data Loss: 0.0046 | Phys Loss: 0.0056 | β: 0.6304\n",
            "Epoch 43/50 | Loss: 0.0108 | Data Loss: 0.0053 | Phys Loss: 0.0055 | β: 0.6297\n",
            "Epoch 44/50 | Loss: 0.0101 | Data Loss: 0.0043 | Phys Loss: 0.0058 | β: 0.6291\n",
            "Epoch 45/50 | Loss: 0.0099 | Data Loss: 0.0042 | Phys Loss: 0.0057 | β: 0.6281\n",
            "Epoch 46/50 | Loss: 0.0096 | Data Loss: 0.0043 | Phys Loss: 0.0054 | β: 0.6280\n",
            "Epoch 47/50 | Loss: 0.0100 | Data Loss: 0.0042 | Phys Loss: 0.0058 | β: 0.6270\n",
            "Epoch 48/50 | Loss: 0.0098 | Data Loss: 0.0042 | Phys Loss: 0.0056 | β: 0.6261\n",
            "Epoch 49/50 | Loss: 0.0098 | Data Loss: 0.0042 | Phys Loss: 0.0056 | β: 0.6251\n",
            "Epoch 50/50 | Loss: 0.0098 | Data Loss: 0.0042 | Phys Loss: 0.0056 | β: 0.6243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 50\n",
        "beta_history, loss_history = train(model, optimizer, plant_data['SG'], num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfL0kAdQvVAG",
        "outputId": "a5d1fe3b-04a6-48fb-9319-d6f49b2b0c3a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50 | Loss: 0.0786 | Data Loss: 0.0738 | Phys Loss: 0.0049 | β: 0.6250\n",
            "Epoch 2/50 | Loss: 0.0788 | Data Loss: 0.0736 | Phys Loss: 0.0052 | β: 0.6256\n",
            "Epoch 3/50 | Loss: 0.0787 | Data Loss: 0.0736 | Phys Loss: 0.0051 | β: 0.6265\n",
            "Epoch 4/50 | Loss: 0.0785 | Data Loss: 0.0737 | Phys Loss: 0.0048 | β: 0.6262\n",
            "Epoch 5/50 | Loss: 0.0787 | Data Loss: 0.0736 | Phys Loss: 0.0051 | β: 0.6279\n",
            "Epoch 6/50 | Loss: 0.0784 | Data Loss: 0.0736 | Phys Loss: 0.0048 | β: 0.6298\n",
            "Epoch 7/50 | Loss: 0.0789 | Data Loss: 0.0736 | Phys Loss: 0.0053 | β: 0.6308\n",
            "Epoch 8/50 | Loss: 0.0783 | Data Loss: 0.0735 | Phys Loss: 0.0048 | β: 0.6328\n",
            "Epoch 9/50 | Loss: 0.0788 | Data Loss: 0.0736 | Phys Loss: 0.0051 | β: 0.6337\n",
            "Epoch 10/50 | Loss: 0.0787 | Data Loss: 0.0736 | Phys Loss: 0.0051 | β: 0.6352\n",
            "Epoch 11/50 | Loss: 0.0785 | Data Loss: 0.0736 | Phys Loss: 0.0049 | β: 0.6380\n",
            "Epoch 12/50 | Loss: 0.0786 | Data Loss: 0.0738 | Phys Loss: 0.0048 | β: 0.6374\n",
            "Epoch 13/50 | Loss: 0.0790 | Data Loss: 0.0736 | Phys Loss: 0.0053 | β: 0.6386\n",
            "Epoch 14/50 | Loss: 0.0789 | Data Loss: 0.0736 | Phys Loss: 0.0053 | β: 0.6392\n",
            "Epoch 15/50 | Loss: 0.0788 | Data Loss: 0.0736 | Phys Loss: 0.0052 | β: 0.6408\n",
            "Epoch 16/50 | Loss: 0.0788 | Data Loss: 0.0736 | Phys Loss: 0.0051 | β: 0.6412\n",
            "Epoch 17/50 | Loss: 0.0786 | Data Loss: 0.0736 | Phys Loss: 0.0049 | β: 0.6430\n",
            "Epoch 18/50 | Loss: 0.0784 | Data Loss: 0.0737 | Phys Loss: 0.0048 | β: 0.6434\n",
            "Epoch 19/50 | Loss: 0.0788 | Data Loss: 0.0736 | Phys Loss: 0.0052 | β: 0.6445\n",
            "Epoch 20/50 | Loss: 0.0788 | Data Loss: 0.0736 | Phys Loss: 0.0052 | β: 0.6449\n",
            "Epoch 21/50 | Loss: 0.0788 | Data Loss: 0.0736 | Phys Loss: 0.0052 | β: 0.6455\n",
            "Epoch 22/50 | Loss: 0.0787 | Data Loss: 0.0736 | Phys Loss: 0.0051 | β: 0.6469\n",
            "Epoch 23/50 | Loss: 0.0787 | Data Loss: 0.0736 | Phys Loss: 0.0051 | β: 0.6473\n",
            "Epoch 24/50 | Loss: 0.0788 | Data Loss: 0.0737 | Phys Loss: 0.0051 | β: 0.6471\n",
            "Epoch 25/50 | Loss: 0.0787 | Data Loss: 0.0736 | Phys Loss: 0.0051 | β: 0.6483\n",
            "Epoch 26/50 | Loss: 0.0787 | Data Loss: 0.0736 | Phys Loss: 0.0051 | β: 0.6491\n",
            "Epoch 27/50 | Loss: 0.0789 | Data Loss: 0.0736 | Phys Loss: 0.0053 | β: 0.6505\n",
            "Epoch 28/50 | Loss: 0.0788 | Data Loss: 0.0736 | Phys Loss: 0.0052 | β: 0.6512\n",
            "Epoch 29/50 | Loss: 0.0787 | Data Loss: 0.0736 | Phys Loss: 0.0051 | β: 0.6516\n",
            "Epoch 30/50 | Loss: 0.0787 | Data Loss: 0.0736 | Phys Loss: 0.0050 | β: 0.6520\n",
            "Epoch 31/50 | Loss: 0.0786 | Data Loss: 0.0737 | Phys Loss: 0.0048 | β: 0.6526\n",
            "Epoch 32/50 | Loss: 0.0786 | Data Loss: 0.0736 | Phys Loss: 0.0050 | β: 0.6538\n",
            "Epoch 33/50 | Loss: 0.0788 | Data Loss: 0.0736 | Phys Loss: 0.0052 | β: 0.6546\n",
            "Epoch 34/50 | Loss: 0.0788 | Data Loss: 0.0736 | Phys Loss: 0.0051 | β: 0.6555\n",
            "Epoch 35/50 | Loss: 0.0785 | Data Loss: 0.0737 | Phys Loss: 0.0048 | β: 0.6563\n",
            "Epoch 36/50 | Loss: 0.0789 | Data Loss: 0.0736 | Phys Loss: 0.0053 | β: 0.6564\n",
            "Epoch 37/50 | Loss: 0.0787 | Data Loss: 0.0736 | Phys Loss: 0.0051 | β: 0.6568\n",
            "Epoch 38/50 | Loss: 0.0787 | Data Loss: 0.0736 | Phys Loss: 0.0051 | β: 0.6577\n",
            "Epoch 39/50 | Loss: 0.0787 | Data Loss: 0.0736 | Phys Loss: 0.0051 | β: 0.6588\n",
            "Epoch 40/50 | Loss: 0.0785 | Data Loss: 0.0736 | Phys Loss: 0.0049 | β: 0.6595\n",
            "Epoch 41/50 | Loss: 0.0787 | Data Loss: 0.0736 | Phys Loss: 0.0051 | β: 0.6604\n",
            "Epoch 42/50 | Loss: 0.0787 | Data Loss: 0.0736 | Phys Loss: 0.0050 | β: 0.6607\n",
            "Epoch 43/50 | Loss: 0.0785 | Data Loss: 0.0736 | Phys Loss: 0.0049 | β: 0.6618\n",
            "Epoch 44/50 | Loss: 0.0791 | Data Loss: 0.0738 | Phys Loss: 0.0052 | β: 0.6594\n",
            "Epoch 45/50 | Loss: 0.0788 | Data Loss: 0.0736 | Phys Loss: 0.0053 | β: 0.6601\n",
            "Epoch 46/50 | Loss: 0.0788 | Data Loss: 0.0736 | Phys Loss: 0.0053 | β: 0.6615\n",
            "Epoch 47/50 | Loss: 0.0788 | Data Loss: 0.0736 | Phys Loss: 0.0052 | β: 0.6618\n",
            "Epoch 48/50 | Loss: 0.0787 | Data Loss: 0.0736 | Phys Loss: 0.0051 | β: 0.6625\n",
            "Epoch 49/50 | Loss: 0.0784 | Data Loss: 0.0737 | Phys Loss: 0.0047 | β: 0.6631\n",
            "Epoch 50/50 | Loss: 0.0788 | Data Loss: 0.0736 | Phys Loss: 0.0051 | β: 0.6633\n"
          ]
        }
      ]
    }
  ]
}